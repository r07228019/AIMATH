{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要先決定input, output的結構<br>\n",
    "幾層神經網路，每層有幾個神經元<br>\n",
    "每層跟周遭兩層都是fully connected<br>\n",
    "fully connect要決定有幾層和幾個神經元<br>\n",
    "神經網路如果出來只有加權和跟bias，那永遠都是線性，激勵函數可以讓原本單調的線性規則變為非線性<br>\n",
    "可以依據不同分布去選激勵函數<br>\n",
    "sigmoid-->常用(模擬人類神經元的反應)<br>\n",
    "要先設定權重跟bias，才能放到激勵函數中產生結果<br>\n",
    "以權重w1, w2，加上bias，計算後可以得到loss function，我們要取loss function的最小值，所以需要一部部學習，在圖形上選取最小值(微分=0)<br>\n",
    "eta是learning rate，讓訓練學習的過程不要一次前進或後退太多<br>\n",
    "由於初始執會影響學習到的最小值，可能只是局部最小，因此可以換不同初始值試試看，以找到絕對最小值<br>\n",
    "filter不是只有看該點的特性，而是會看其他周遭點的特徵<br>\n",
    "要決定filter的大小和個數<br>\n",
    "把convolution做成矩陣，然後分區塊，每個區塊選出最大值，縮小矩陣<br>\n",
    "做完再傳回正常的身經網路NN<br>\n",
    "<br>\n",
    "RNN 遞迴神經網路<br>\n",
    "RNN神經元會將這次的輸出(h)在傳回作為輸入，所以再加上加權的x1, x2，共會有4個輸入<br>\n",
    "一種有記憶，遞迴的操作<br>\n",
    "要決定有幾個RNN神經元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
