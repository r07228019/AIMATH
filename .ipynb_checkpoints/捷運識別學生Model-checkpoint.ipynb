{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic('env', 'KERAS_BACKEND=tensorflow')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import SGD  #隨機調整\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.datasets import mnist    #資料\n",
    "from keras.utils import np_utils    #轉為分類問題\n",
    "from keras.utils import to_categorical \n",
    "from keras.models import Sequential #神經網路相關套件  標準  \n",
    "from keras.optimizers import Adam \n",
    "from ipywidgets import interact_manual\n",
    "\n",
    "# Keras 建立具分歧及合併結構的神經網路模型\n",
    "from keras.layers import concatenate, add\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "df = pd.read_csv('整理完_合理旅次_訓練格式.csv')\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('4個藍色禁止標誌.csv')\n",
    "df2.head()\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "sta =  df.iloc[0:len(df),1:2] \n",
    "sta.head()\n",
    "t_1 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in df['第一次進站時間']]\n",
    "t_2 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in df['第一次出站時間']]\n",
    "t_3 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in df['最後一次進站時間']]\n",
    "t_4 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in df['最後一次出站時間']]\n",
    "df['第一次進站分鐘']=t_1\n",
    "df['第一次出站分鐘']=t_2\n",
    "df['最後一次進站分鐘']=t_3\n",
    "df['最後一次出站分鐘']=t_4\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "stacode = pd.read_csv('station_code2.csv')\n",
    "stacode2 = stacode.set_index('站名').T.to_dict('int')\n",
    "stacode3 = stacode2[\"代號\"]\n",
    "df['第一次進站地點'] = [ stacode3[i] for i in df['第一次進站地點']]\n",
    "df['第一次出站地點'] = [ stacode3[i] for i in df['第一次出站地點']]\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "x_train = df.loc[:, ['第一次進站地點', '第一次出站地點','第一次進站分鐘','第一次出站分鐘','最後一次進站分鐘','最後一次出站分鐘']] \n",
    "x_train.head()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "card = df.iloc[0:len(df),7] \n",
    "card.head()\n",
    "#y_train0 = np.array (( df.卡種 == 1 ) | ( df.卡種 == 6 )) * 1\n",
    "y_train = np.array (( df.卡種 == 6 )) * 1       #我不要他媽的一般卡\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_train0=y_train[0:20000]\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "x_train0=x_train.iloc[0:20000,] \n",
    "x_train0.shape\n",
    "y_train0.shape\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "len(df['卡種'])\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "x_test0=x_train.iloc[20001:len(df['卡種']),] \n",
    "y_test0=y_train[20001:28035] \n",
    "y_test0.shape\n",
    "\n",
    "\n",
    "# ## 建構神經網路\n",
    "\n",
    "# Activation 使用 \"relu\"\n",
    "# Loss funtion 使用 \"binary_cossentropy\"\n",
    "\n",
    "# ## 組裝神經網路\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "x = Input(shape=(6,))\n",
    "\n",
    "# 不同階層的函數\n",
    "f_1 = Dense(400, activation='sigmoid')\n",
    "f_2 = Dense(200, activation='sigmoid')\n",
    "f_3 = Dense(200, activation='sigmoid')\n",
    "f_4 = Dense(100, activation='sigmoid')\n",
    "f_5 = Dense(100, activation='sigmoid')\n",
    "f_6 = Dense(400, activation='relu')\n",
    "f_7 = Dense(200, activation='sigmoid')\n",
    "f_8 = Dense(200, activation='relu')\n",
    "f_9 = Dense(100, activation='relu')\n",
    "f_10 = Dense(2, activation='softmax')\n",
    "\n",
    "# hiden layer\n",
    "h_11 = f_1(x)\n",
    "h_21 = f_2(h_11)\n",
    "h_22 = f_3(h_11)\n",
    "u1=concatenate([h_21,h_22])\n",
    "h_31 = f_4(u1)\n",
    "h_12 = f_6(x)\n",
    "h_23 = f_7(h_12)\n",
    "h_24 = f_8(h_12)\n",
    "u2=concatenate([h_23,h_24])\n",
    "h_32 = f_9(u2)\n",
    "u3=concatenate([h_31,h_32])\n",
    "h_4 = f_5(u3)\n",
    "\n",
    "y = f_10(h_4)\n",
    "\n",
    "model = Model(x, y)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ## 訓練神經網路\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# model training\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelfit=model.fit(x_train0, y_train0, batch_size=128, epochs=10,validation_split=0.2)\n",
    "\n",
    "\n",
    "# ## 檢視結果\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "score_fork = model.evaluate(x_test0, y_test0)\n",
    "x_test0\n",
    "print('loss: ',score_fork[0],'acc: ',score_fork[1] )\n",
    "\n",
    "\n",
    "# ## 畫圖結果\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "plt.plot(modelfit.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend([\"accuracy\"],loc = \"best\")\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('C:/Users/USER/Desktop/0315運具資料/4個藍色禁止標誌.csv',engine = \"python\",encoding = 'utf-8')\n",
    "dfcard = pd.unique(dft.卡號)   \n",
    "cat = []\n",
    "for i in dfcard:\n",
    "    a = dft[dft.卡號 == i]  #從unique叫出卡號\n",
    "    cat.append([a.iloc[0,5],a.iloc[0,6],a.iloc[0,3],a.iloc[0,4],a.iloc[-1,3],a.iloc[-1,4],a.iloc[0,2],a.iloc[0,7]])\n",
    "dft2 = pd.DataFrame(cat,columns= ['第一次進站地點', '第一次出站地點','第一次進站時間',\n",
    "                               '第一次出站時間','最後一次進站時間','最後一次出站時間','卡種','type'])\n",
    "dft3 = dft2.sort_values(['第一次進站時間','卡種'])\n",
    "stacode = pd.read_csv('C:/Users/USER/Desktop/0315運具資料/station_code2.csv',engine = \"python\")\n",
    "stacode2 = stacode.set_index('站名').T.to_dict('int')\n",
    "stacode3 = stacode2[\"代號\"]\n",
    "dft3['第一次進站地點'] = [ stacode3[i] for i in dft3['第一次進站地點']]\n",
    "dft3['第一次出站地點'] = [ stacode3[i] for i in dft3['第一次出站地點']]\n",
    "t_1 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in dft3['第一次進站時間']]\n",
    "t_2 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in dft3['第一次出站時間']]\n",
    "t_3 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in dft3['最後一次進站時間']]\n",
    "t_4 = [(int(e[: 2])*60 + int(e[3: 5]))/1440 for e in dft3['最後一次出站時間']]\n",
    "dft3['第一次進站時間']=t_1\n",
    "dft3['第一次出站時間']=t_2\n",
    "dft3['最後一次進站時間']=t_3\n",
    "dft3['最後一次出站時間']=t_4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
